% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/vocab.R
\name{subembed}
\alias{subembed}
\title{\code{\link[=subembed]{subembed()}} subsets a (commonly large) pre-trained word-vector matrix
into a smaller, one vector per term, embedding matrix.}
\usage{
subembed(vocab, embeddings, nbuckets = attr(vocab, "nbuckets"),
  max_in_bucket = 30)
}
\arguments{
\item{embeddings}{embeddings matrix. The terms dimension must be named. If
both \code{\link[=colnames]{colnames()}} and \code{\link[=rownames]{rownames()}} are non-null, dimension with more
elements is considered term-dimension.}

\item{max_in_bucket}{At most this many embedding vectors will be averaged
into each unknown or missing bucket (see details). Lower number results in
faster processing. For large \code{nbuckets} this number might not be
reached due to the finiteness of the \code{embeddings} vocabulary, or even
result in \code{0} embeddings being hashed into a bucket producing \code{[0 0 ...]}
embeddings for some buckets.}
}
\description{
\code{\link[=subembed]{subembed()}} is commonly used in conjunction with sequence generators
(\code{\link[=tix_mat]{tix_mat()}}, \code{\link[=tix_seq]{tix_seq()}} and \code{\link[=tix_df]{tix_df()}}). When a term in a corpus is not
present in a vocabulary (aka unknown), it is hashed into one of the
\code{nbuckets} buckets. Embeddings which are hashed into same bucket are
averaged to produce the embedding for that bucket. Maximum number of
embeddings to average per bucket is controled with \code{max_in_bucket}
parameter.
}
\details{
Similarly, when a term from the vocabulary is not present in the embedding
matrix (aka missing) \code{max_in_bucket} embeddings are averaged to produce the
missing embedding. Different buckets are used for "missing" and "unknown"
embeddings because \code{nbuckets} can be 0.
}
\examples{

subembed(v2, emat)
subembed(v2, t(emat)) # automatic detection of the orientation

vembs <- subembed(v2, emat)
all(vembs[enames, ] == emat[enames, ])

}
